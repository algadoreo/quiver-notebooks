{
  "title": "Meeting with Carlo (July 26, 2018)",
  "cells": [
    {
      "type": "markdown",
      "data": "### Notes by Jamil Shariff"
    },
    {
      "type": "markdown",
      "data": "- agreement that beam product didn't make a whole lot of difference, resolving to be careful about which low-level products or minutiae hold up a first paper henceforth\n\n#### Masks:\n\n- Vpol has good PTEs and could conceivably be used for analysis. High RA (left) and top right corner of LatLon can be problematic. Could be covariance related in the case of the right side\n\n- For the purposes of a semi-competitive upper limit, we shouldn't worry about slightly worse performance in null tests\n\n- Seems like decision is to go for LatLon overall.\n\n- **XFaster**: had to regenerate Planck sims (seed was wrong) reprocessing all maps now \n\n  * This run should be exactly the same as March run (including use of beam12)\n\n  * Only difference is more maps\n\n  * Anne was excluding day 13 because XFaster null tests were not converging\n\n  * Some discussion of including or excluding days that I didn't catch\n\n- XFaster Spider 90x150 is being run now, foregrounds will be turned back on soon. Carlo will put a post back up, but doesn't expect a different result from before\n\n- Ensembles are now 1000 noise sims, 500 signal sims, 500 transfer sims, \n\n- Biggest XFaster bias comes from noise, so in general it wants more noise sims than signal to converge well. For null tests we really care about this too\n\n- **Problem:** we're looking at several months to get the null tests through (bottleneck is generating the maps).\n\n- Steve: we want to run both pipelines through all of the null tests. We could start writing after seeing only a subset of the sims and they will all be done by the time we finish writing\n\n- Could do one null test that has 1000 and 500 and then try using a subset (e.g. fewer noise sims) and see if it's okay\n\n- Some discussion of how long null tests maps should take on Niagara (separate channel set for every null test, and also everything is chunked)\n\n- Carlo: do we really need to do all 9 null tests in both pipelines if say, one of them agrees? Estimators should agree \\*statistically\\* if both are unbiased\n\n- Agreement was really good between pipelines last time we compared them, after sorting out differences in how transfer functions were handled between the two\n\n- **Paper(s):** We should suggest beginning work on _Overleaf_ on some number of papers, as that tends to push things forward a fair bit (this is now on the telecon agenda for today along with issues of unblinding). The other advantage of writing is that it helps triaging things (e.g. if NILC is not ready but you can submit without it, do you wait for it?). \n\n- Carlo also pointed out that while NILC provides you with nice looking component separated maps and a sense of whether your foreground estimate is consistent with other methods, you do not understand the statistics of said maps, therefore you do not carry NILC farther than that point in the analysis.\n\n- **There is a _significant_ need for high-level support/executive decisions from Barth/Bill**, including such issues as who is assigned to which sections on a given paper, who is the first author (or corresponding author if we're going with Spider Collaboration et al.)\n\n- We in this room feel strongly that we should put out a **Spider instrument paper** and that there is no reason that it cannot have already been written. However, there was not support for this from Ruhl, Bill, or Barth."
    }
  ]
}